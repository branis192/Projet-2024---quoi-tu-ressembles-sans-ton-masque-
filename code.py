# -*- coding: utf-8 -*-
"""MiniProjet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1avBU4_dGb8H440LPxSC3FxaAvTaTINsT

# Mini Projet 2024 - à quoi tu ressembles sans ton masque ?

Avec la pandémie de la Covid-19, nous avons appris à porter des masques quotidiennement.
Désormais la moitié de notre visage est cachée nous laissant le regard pour seul moyen d'expression visible. Cette opération de restaurer le visage s'apparente à un domaine en traitement d'images et de vidéos appelé **inpainting**. En effet, les pixels correspondant à la zone du masque (modélisé par un rectangle) sont mis à 0. Et l'ACP et les **eigenfaces** permettent, entre autres, de restaurer la zone dégradée.  


L'**objectif de ce mini projet** consiste à combler la zone de masque par un visage qui est le plus semblable à l'aide de l'ACP et des $k$ plus proches voisins.
"""

import numpy as np
import sklearn
import matplotlib.pyplot as plt
from matplotlib import image
from random import *

"""## Chargement des données

La base de données sur laquelle ce projet est appliqué est une collection d'images utiles pour mener des expériences en psychologie (*Psychological Image Collection at Stirling* (PICS) :http://pics.stir.ac.uk).

<img src="files/base.PNG" width="800" height="600"  >

Elle comporte 32 personnes (16 hommes et 16 femmes) avec 6 postures/expressions  faciales : 2 postures (face et trois quart face) et 3 émotions différentes par posture.


"""

# Chargement des données de visages entiers : 192 x 120000
X_Data=np.load('Data.npy')

# Dimensions des images
nblignes=400
nb_colonnes=300

plt.imshow(np.reshape(X_Data[0,:],(nblignes,nb_colonnes)))
plt.title('Exemple de visage')

# Chargement des données de visages masqués : 192 x 120000
X_DataMask=np.load('DataMask.npy')

plt.imshow(np.reshape(X_DataMask[0,:],(nblignes,nb_colonnes)))
plt.title('Exemple de visage masqué')

"""# Création base d'apprentissage"""

# Création de la base d'apprentissage : exemple à modifier
X_App=X_DataMask[np.arange(0,48,3),:]


# Affichage des visages masqués de la base d'apprentissage
plt.figure(figsize=(10,10))
compt=0
for i in range(0,X_App.shape[0]):
    im=np.reshape(X_App[i,:],(400,300))
    plt.subplot(4,4,compt+1)
    compt=compt+1
    plt.imshow(im,cmap='gray')

plt.show()

"""##  Eigenfaces et réduction de dimensions par ACP

Complétez la fonction *eigenfaces*, qui vise à calculer les axes
principaux des images d'apprentissage à partir des vecteurs propres associés
aux $n-1$ valeurs propres non nulles de la matrice de variance/covariance
$\Sigma$ des données/.


La notion d'eigenfaces provient du travail de M. Turk et A. Pentland intitulé «Eigenfaces for
Recognition» : https://www.mitpressjournals.org/doi/pdfplus/10.1162/jocn.1991.3.1.71


<img src="files/Eigenfaces.PNG" width="600" height="500"  >

**Remarque :**  la
    fonction *np.linalg.eig* ne peut pas être directement appliquée à $\Sigma$. En
    effet, sa taille $p\times p$ est gigantesque ($p = 120000$). Or, pour une
    matrice $\text{M}$ quelconque, $\text{M}^\top \text{M}$ et
    $\text{M}\,\text{M}^\top$ ont les mêmes valeurs propres \emph{non nulles}.
    On peut donc appliquer la fonction \verb!eig! à $\Sigma_2 = \text{X}_c \,
    \text{X}_c^\top/n$, de taille $n\times n$ beaucoup plus petite, pour
    calculer les valeurs propres non nulles de $\Sigma$.
"""

"""## Reconnaissance par kppv

En tirant aléatoirement une image de test, parmi les 32 personnes et les 6 postures faciales disponibles dans la base de données complète, complétez une fonction pour trouver l'individu (personne+posture) et la distance du proche voisin dans la base d'apprentissage qui est le plus proche de l'image de test (vous pouvez utiliser et adapter la fonction \texttt{kppv} que vous avez écrite lors du TP2).
"""
def eigenface(X_App):

  ComposantesPrincipales =[]

  x_moyen = np.mean(X_App,axis = 0)

  x_centred = X_App - x_moyen

  matrix_cov1 = np.dot(x_centred,np.transpose(x_centred)) / x_centred.shape[0]


  v_p1 , vec_p1 = np.linalg.eig(matrix_cov1)

  vecsigma1 = np.dot(np.transpose(x_centred),vec_p1)

  plt.figure(figsize=(10,10))

  print(1)
  compt=0
  for i in range(0,vecsigma1.shape[1]):
    im=np.reshape(vecsigma1[:,i],(400,300))
    plt.subplot(4,4,compt+1)
    compt=compt+1
    plt.imshow(im,cmap='gray')

  plt.show()

  vecsigma1.sort()


  for i in range(vecsigma1.shape[1]) :

    ComposantesPrincipales.append(np.dot(X_App,vecsigma1[:,i]))

  print(ComposantesPrincipales)

  return ComposantesPrincipales



eigenface(X_App)
# à vous

"""## Reconstruction

A partir de la question précédente, implémentez la reconstruction de la zone du masque  en remplaçant la zone correspondant au masque par la zone de l'image de la base d'apprentissage de visages entiers la plus proche dans l'espace défini par les eigenfaces masqués.

def kppv(image,imagemask):



    # Initialisation du vecteur d'etiquetage des images tests
    Partition = np.zeros((16,1));

    # Boucle sur les vecteurs test de l'ensemble de l'evaluation
    for i in range(5):

        #print('Image test n',i)

        # Calcul des distances entre les vecteurs de test
        # et les vecteurs d'apprentissage (voisins)

        distance = euclidean_distances(imagemask[i].reshape((1,-1)),image)

        # # On ne garde que les indices des K + proches voisins

        kpp = np.argsort(distance[0])[0]

        print(kpp)
        print(i)

        Na=X_Data[kpp]
        Nt=X_DataMask[i]

        ImExple1=np.reshape(Nt,(400,300))
        plt.imshow(ImExple1,cmap = "gray")
        plt.show()

        ImExple2=np.reshape(Na,(400,300))
        plt.imshow(ImExple2,cmap = "gray")
        plt.show()



    return Partition



kppv(X_Data,X_DataMask)


"""

# Dimensions du masque
ligne_min = 220
ligne_max = 350
colonne_min = 60
colonne_max = 260

"""# Evaluation

Pour l'évaluation, une possibilité serait d'estimer la distribution des distances au plus proche voisin dans le cas de la même personne avec une émotion différente et une posture différente.

En fonction de cette distribution, on peut définir une distance seuil à partir de laquelle on peut envoyer un message en précisant que
-la personne la + proche n'est pas la bonne personne associée à l'image requête

**Autre piste :** Affiner l'étude aussi lorsque la personne idenfiée correspond à l'image requête avec une autre distance spécifique pour une posture différente voire pour une émotion différente ? Plein de possiblités pour cette étude sur l'évaluation de la reconstruction.
"""



